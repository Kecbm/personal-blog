---
layout: post
title: 13 coisas que aprendi em 1 ano usando Serverless em produção
canonical_url: https://medium.com/@fidelissauro/13-coisas-que-aprendi-em-1-ano-usando-serverless-em-produ%C3%A7%C3%A3o-40e4e5e50470?source=rss-fc2fda5e9bc2------2
---

<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*D55D8ZOM94QZ-E3G4NftjQ.jpeg" /><figcaption>Photo by <a href="https://unsplash.com/photos/m-VhHYQ4yFg?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Nazarii Yurkov</a> on <a href="https://unsplash.com/search/photos/builder?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p>O objetivo desse artigo é mostrar uma série de aprendizados e dicas de alguém precisou escalar meia dúzia de funções lambda criadas pra pequenas automações de infraestrutura, tarefas agendadas, resposta automática pra alertas até equipes grandes de produtos inteiramente construídos utilizando Serverless por meio de FaaS com AWS Lambda, mas essas dicas podem ser absorvidas por qualquer um que seja o vendor que você estiver utilizando.</p><p>Sempre tive curiosidade pela adoção de tecnologias Serverless na resolução de problemas, e desde o primeiro contato sempre busquei formas de trazer a utilização desse tipo de tecnologia pro meu dia a dia. Aqui vai o meu compiladão com as principais dicas que eu gostaria que alguém tivesse me dado quando comecei a desbravar esse tipo de arquitetura.</p><h3>1. Use um orquestrador, e se possível o Serverless Framework</h3><p>A primeira apresentação que tive com o AWS Lambda me mostrou uma abordagem simplista de “gerar zipzinhos” com seu código, selecionar um runtime da sua linguagem, e botar pra rodar. Depois criar um endpointzinho na mão no API Gateway e integrar naquela Lambda e pá. Tenho um Hello World “sem servidor”. A primeira dúvida, de quem veio de equipes de desenvolvimento de ERP e SaaS é “Beleza, mas não da pra usar no dia a dia”. Com 10, 20, 30 funções, em uma equipe mais dinâmica de desenvolvimento essa rotina do build do “zipzinho” e configurações manuais se torna impraticável.</p><p>Utilizar um orquestrador via CLI faz com que seja possível integrar seu deploy, multistage, testes a qualquer pipeline de entrega contínua, e ele cobre muita configuração manual que você teria que executar conforme sua aplicação e equipe escalam.</p><p>Existem vários tipos de orquestradores, o meu favorito é a figurinha carimbada do assunto, o <strong>Serverless Framework</strong>.</p><p>O <strong>Serverless Framework</strong> cobre vários vendors de mercado como <strong>Google Cloud</strong>, <strong>Azure</strong>, <strong>IBM</strong>, <strong>Fn</strong> e o que nós usamos, o saudoso <strong>AWS Lambda</strong>.</p><p><a href="https://serverless.com">Serverless - The Serverless Application Framework powered by AWS Lambda, API Gateway, and more</a></p><h3>2. Use/Crie um boilerplate de projeto</h3><p>Quando você trabalha sozinho assuntos como organização, padronização e reaproveitamento de código não são coisas tão importantes assim. Quando você precisa escalar esse tipo de tecnologia pra um ou mais times de desenvolvimento, é necessário existir um consenso de padrões e boas práticas, e também de um centralizador de bibliotecas. Afinal é inviável ficar replicando modificações incrementais, correções bugs em 20, 30 versões diferentes da mesma biblioteca. Por isso crie uma estruturação minima de código para seus projetos. Nossa proposta de organização e estruturação está pública e open source. Esse boilerplate é utilizado desde os pequenos até os grandes projetos, e ele também está lá no <a href="https://github.com/serverless/serverless#v1-projects"><strong>README</strong></a> oficial do Serverless Framework do Github.</p><p><a href="https://github.com/msfidelis/serverless-architecture-boilerplate">msfidelis/serverless-architecture-boilerplate</a></p><h3>3. Testes, eles precisam existir aqui também</h3><p>Mais um ponto crucial da velha escola que precisamos adotar dentro desse novo paradigma. Aplicações construídas sobre arquiteturas Serverless são naturalmente muito difíceis de serem testados por normalmente consumirem muitos recursos vendor como filas do SQS, Streams do Kinesis, Tabelas do Dynamo, Buckets do S3 e etc.</p><p>No caso, utilizamos 100% de NodeJS em nossos projetos, e aproveitamos a maravilhosa stack de testes que o Javascript nos provê via comunidade. No caso utilizamos:</p><p><a href="https://mochajs.org"><strong>Mocha</strong></a> — Lib de testes unitários e integração<br><a href="https://www.chaijs.com"><strong>Chai</strong></a> — Lib de Assertation / Expectation para TDD e BDD</p><p>Também é possível utilizar o o <a href="https://github.com/hapijs/lab"><strong>Lab</strong></a> da Hapi caso seja de sua preferência.</p><p>O teste de funções lambda seguem um padrão até que simples. Normalmente a AWS injeta uma função de callback , na qual normalmente usamos para encerrar a execução da mesma. O segredo é que vamos injetar essa função de callback nas funções que queremos testar e fazer os assertations do retorno.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/982/0*i3wi9ky3HEcwJr5C" /></figure><h3>4. Seu Cloud rodando local</h3><p>É necessário que seus desenvolvedores consigam simular localmente alguns recursos especificos da núvem que você está utilizando. No nosso caso, usamos em peso vários serviços fornecidos pela AWS. Para diminuir a diferença entre os ambiente de desenvolvimento local com os ambientes de homolação, produção e etc, será necessário conseguir utilizar alguns desses principais serviços localmente.</p><p>Adotamos algumas estratégias matadoras pra resolver esse problema;</p><ol><li>O Plugin Serverless Offline;</li><li>Muito Docker;</li><li>Plugins e mais plugins da comunidade;</li></ol><p>Atraves do <strong>serverless-offline</strong>, plugin do Serverless Framework, conseguimos realizar chamadas de API localmente, diretamente pela porta 3000</p><pre>serverless offline start --stage local</pre><ul><li><a href="https://github.com/dherault/serverless-offline">dherault/serverless-offline</a></li><li><a href="https://github.com/msfidelis/serverless-offline-sqs-esmq">msfidelis/serverless-offline-sqs-esmq</a></li><li><a href="https://github.com/ajmath/serverless-offline-scheduler">ajmath/serverless-offline-scheduler</a></li><li><a href="https://github.com/svdgraaf/serverless-pseudo-parameters">svdgraaf/serverless-pseudo-parameters</a></li></ul><p>Rodamos o Serverless Offline via Docker também. Tentamos conteinerizar tanto o ambiente do serverless offline quanto as dependências de infraestrutura mockada da AWS:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/df82b3f5df8704630695ebfcd429f381/href">https://medium.com/media/df82b3f5df8704630695ebfcd429f381/href</a></iframe><p>Separamos nossos outros serviços da AWS emulados localmente em outros containers, quando isso cresce demais, utilizamos o Localstack. Até o numero de containers virar um problema, gostamos de separar tudo.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/cc7d0a456cc3b2de93417f375f1f451e/href">https://medium.com/media/cc7d0a456cc3b2de93417f375f1f451e/href</a></iframe><p>Segue alguns recursos que usamos pra mockar localmente a infra da AWS.</p><ul><li><a href="https://github.com/localstack/localstack">GitHub - localstack/localstack: 💻 A fully functional local AWS cloud stack. Develop and test your cloud &amp; Serverless apps offline</a></li><li><a href="https://www.npmjs.com/package/serverless-dynamodb-local">serverless-dynamodb-local</a></li><li><a href="https://www.npmjs.com/package/serverless-s3-local">serverless-s3-local</a></li><li><a href="https://github.com/softwaremill/elasticmq">softwaremill/elasticmq</a></li></ul><h3>5. Aplicação de verdade, roda em VPC</h3><p>Um dos critérios mais importantes para criar aplicações de verdade, robustas e seguras na AWS, será necessário ir além do básico dentro das configurações de rede. Ou seja, precisaremos gastar um tempo projetando a rede interna do nossa aplicação.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/22c89a54a83e41067e7c20df245d9567/href">https://medium.com/media/22c89a54a83e41067e7c20df245d9567/href</a></iframe><h4>Segue algumas dicas importantes:</h4><ul><li>Escolha pelo menos duas zonas de disponibilidade. Isso vai garantir uma redundância caso o serviço do lambda venha a falhar em alguma delas.</li><li>Cada zona de disponibilidade deverá ter no mínimo uma subnet publica e uma privada para rodar a aplicação. Isso garante o tráfego pra internet e o isolamento de execução das funções da DMZ.</li><li>As lambdas deverão ser configuradas para rodar somente nas subnets privadas. Sempre.</li><li>Crie mais uma subnet em cada AZ sem acesso a internet para fazer deploy dos bancos de dados SQL, <strong>Redis</strong>, <strong>Memcached</strong>, <strong>Elasticsearch</strong> e derivados. Isso te garante uma camada a mais de segurança e isolamento de recursos.</li><li>Crie um<strong> NAT Gateway</strong> com IP fixo em uma das subnets públicas, e faça o roteamento das <strong>Route Tables</strong> de todo o tráfego das subnets privadas para o NAT Gateway — Isso é importante, porque assim todas as requisições vão sair pra internet sempre com o mesmo IP. Uma hora ou outra você vai se deparar com algum vendor, parceiro e etc que vai necessitar de um IP fixo do seu lado pra alguma liberação, e vai te poupar um estresse do tipo &quot;<em>COMO QUE EU VOU FAZER LAMBDA TER IP FIXO, OS CARA TA DOIDO</em>&quot;. É possivel, e mais fácil resolver isso logo de cara.</li><li>Crie sempre suas subnets privadas com uma máscara de subnet baixa. Isso vai garantir uma quantidade significativa de IP&#39;s disponiveis. A quantidade de lambdas em execução vai se limitar pelo número de IP&#39;s disponiveis entre as subnets indicadas pra elas rodarem. Normalmente as subnets de aplicação, fazemos deploy com a notação /20, isso nos dá em torno de <strong>4094</strong> IP&#39;s em cada subnet para execução de lambdas. Da pra escalar bastante. Nas auxiliares fazemos o deploy com a notação padrão/24 mesmo.</li></ul><h3>6. Segurança na AWS</h3><p>Padrões de Firewall, monitoramento e segurança são necessários pra garantir a estabilidade de uma aplicação, esteja seguindo qualquer padrão quer seja. Existem várias soluções de firewall e CDN no mercado pra que você consiga colocar na frente da sua API ou aplicação. No nosso caso adotamos uma arquitetura bacana utilizando CloudFront na frente da nossa API.</p><p>Mas CloudFront?? CDN? Cache?? Na frente de uma API??</p><p>Sim. Utilizamos o Cloudfront, mas sem cachear nada, passando todo o conteúdo para a origem. Mas pra que isso? Simples! O AWS WAF.</p><p>Até o presente momento, ainda não é possível anexar regras do AWS WAF diretamente do API Gateway em todas as regiões. Dos nossos serviços, só anexamos diretamente no que está rodando na Virginia. Nas demais localizações aproveitamos essa arquitetura. Por enquanto.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/527/1*8iJi3vOdjQ6U7xmY2xDyxQ.png" /></figure><p>Normalmente redirecionamos os logs das nossas regras do WAF pra um Stream do Kinesis e em seguida direcionamos para um cluster de Elasticsearch pra análise e monitoramento.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*SptdrbfChM3Tf8TjFfbVvw.png" /></figure><h3>7. Bancos SQL são possíveis!</h3><p>Na maioria dos exemplos que encontramos sobre Serverless, em 200% só se fala no querido <strong>DynamoDB</strong>. Mas essa realidade de persistência de dados pode ser estendida ao bom e velho SQL se necessário, abrindo o leque pra bancos <strong>MySQL</strong>, <strong>MariaDB</strong>, <strong>PostgreSQL</strong>, <strong>SQL Server</strong>, <strong>Oracle</strong> e etc. Porém são necessários alguns pontos de atenção:</p><ol><li>Sua aplicação deverá estar rodando dentro de um contexto de VPC</li><li>Será necessário anexar uma security group a execução das suas funções lambda</li><li>Esse security group dos runtimes deverão estar autorizados na porta do serviço do banco de dados, seja ele RDS ou não. Caso esteja utilizando um banco de dados em algum outro lugar, autorize o IP de saída da sua rede. Lembra que eu te falei que vai ser importante a qualquer momento?</li><li>Cuidado com o pool de conexões, talvez dê ruim e seu banco venha a ficar indisponível dependendo do throughput das suas funções lambda.</li></ol><h3>8. Bancos NoSQL, Memory Cache, Storage são seus melhores amigos</h3><p>Faça muito uso de recursos como o <strong>DynamoDB</strong> pra escalar escrita e leitura em lotes. Mas cuidado!</p><p>Use muito memory cache como clusters de <strong>Redis</strong> e <strong>Memcached</strong> para tirar carga dos bancos de dados. No caso do DynamoDB, pode ficar caro escalar muito Write / Read com muita frequência, e os bancos SQL, bom, da velha escola, eles são sempre o gargalo mais chato.</p><p>Então use a abuse da velha escola de arquitetura pra esse novo paradigma. Muita coisa pode ser reaproveitada e até melhorada nesse novo contexto de desenvolvimento.</p><h3>9. Entregue tudo por uma Pipeline</h3><p>Mesmo com um orquestrador, ainda existem problemas a serem lidados com escala de times e deploys diários. O ideal é manter o produto sendo entregue sempre por uma pipeline de entrega continua, onde você vai garantir a estabilidade e qualidade o seu código serverless pra qualquer stage que você estiver trabalhando.</p><p>O que podemos incluir numa pipeline pra ajudar a garantir os padrões de qualidade que eu necessito no meu projeto em Serverless? Segue uma listinha:</p><ul><li>Testes unitários e de integração (Mocha, Chai, Lab)</li><li>Syntax Check &amp; Design Patterns (jslint, jshint, standard)</li><li>Documentação &amp; GMUD (Pra processos mais burocráticos)</li><li>Segurança (npm audit, SourceClear, retire.js, arachni)</li></ul><p>Você pode utilizar o que você quiser, existem ótimas opções de mercado e Open Source como <strong>CircleCI</strong>, <strong>CodeShip</strong>, <strong>Jenkins</strong> e etc. Aqui entregamos todos os nosso produtos e funções auxiliares por meio da stack do <strong>CodePipeline</strong> da AWS. Motivo? Podemos entregar desde o projeto mais simples até os mais complexos com a mesma ferramenta. Normalmente adicionamos os steps de build em um arquivo `buildspec.yml`.</p><p>Segue um exemplo:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c6453f2c9ae3146c605ccb5cc35e3f5e/href">https://medium.com/media/c6453f2c9ae3146c605ccb5cc35e3f5e/href</a></iframe><p>Utilizamos nosso orquestrador via CLI pra automatizar uma entrega de código continua em produção.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*_XnytMmb7WIZRyELlhRjsg.png" /></figure><p>Disponibilizamos também nossa pipeline genérica pra escalar projetos Serverless em produção, é bem simples de usar e evoluir a complexidade dos projetos caso necessário. Segue em anexo.</p><p><a href="https://github.com/msfidelis/serverless-pipeline">msfidelis/serverless-pipeline</a></p><h3>10. Promova flexibilidade de ambientes</h3><p>Da mesma forma que costumamos criar diversos stages de desenvolvimento pra ter testes mais fiéis antes de subir uma feature pra uma gama maior de clientes em aplicações mais convencionais, as vezes será necessário aplicar isso no nosso processo de desenvolvimento da mesma forma. Utilizando um orquestrador como o Serverless Framework, fazer isso fica mais fácil. Basta adaptar a sua pipeline de integração e ser feliz!</p><pre>serverless deploy -v --stage homologacao</pre><h3>11. Variáveis de ambiente</h3><p>Aproveitando a dica anterior, você vai precisar modificar sem duvida alguma algumas configurações entre seu ambiente de stage, homolog, prod, nem que seja um apontamento de bancos, credenciais de ambientes de produção pra homologação, limites, prefixos e uma série de coisas que a gente só toma ciência depois que nossa aplicação cresce.</p><p>Fazemos um load no serverless.yml dinamicamente com as variáveis de ambiente do stage em contexto, que passamos durante o deploy, no caso:</p><pre>serverless deploy -v --stage develop</pre><p>Iremos carregar o arquivo configs/develop.yml com as variáveis desse ambiente. Um truque bem simples e legal.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/aec61d7265343976ec4f0788d837ff4a/href">https://medium.com/media/aec61d7265343976ec4f0788d837ff4a/href</a></iframe><p>O AWS lambda oferece recursos de variáveis de ambiente e conseguimos trabalhar bem com esse recurso utilizando o<strong> Serverless Framework</strong>, porém as vezes não é muito seguro trabalhar com tokens, senhas, chaves de criptografia e deixar isso diretamente no painel AWS Lambda. Minha sugestão é utilizar a biblioteca <strong>node-config</strong> ou o saudoso <strong>dotenv.</strong></p><ul><li><a href="https://github.com/lorenwest/node-config">lorenwest/node-config</a></li><li><a href="https://github.com/motdotla/dotenv">GitHub - motdotla/dotenv: Loads environment variables from .env for nodejs projects.</a></li></ul><h3>12. Workers e o processamento desacoplado</h3><p>É possível escalar Workers utilizando AWS Lambda, porém isso nem sempre é tão simples dependendo do caso. Podemos criar uma estrutura básica de worker que escuta uma fila do <strong>SQS</strong>, ou um <strong>Redis</strong>, <strong>Kafka</strong>, <strong>RabbitMQ</strong> e etc, porém como vocês já devem saber nessa altura do campeonato, devemos trabalhar com timeout e memória durante a execução de uma função lambda. No momento que escrevo este post, o máximo permitido no tempo de execução é 15 minutos.</p><p>Minha pra evitar o timeout durante o processamento de muitos itens de forma assíncrona, minha sugestão é sempre dividir o processamento de um lote de itens em lotes menores, e encaminhar esses lotes menores pra diferentes funções lambdas executarem em paralelo.</p><ol><li>Uma lambda é encarregada de puxar os lotes de mensagens de uma fila qualquer;</li><li>Essa lambda divide os itens em pequenos lotes de 5, 10, 20, 40 itens, que seja;</li><li>Essa lambda é encarregada de evocar o processamento de uma nova lambda responsável por executar cada um desses pequenos lotes de itens;</li></ol><h3>13. Monitore tudo, mas tudo mesmo</h3><p>Aplicações Serverless herdam um pouco do cenário de microserviços tanto no aspecto positivo quanto no negativo, principalmente em questão de monitoramento. Ainda não existe nenhuma solução consolidada de APM pra serviços Serverless. Com o crescimento da aplicação, problemas vão surgir, e você vai se dar conta de que as métricas básicas que são provisionadas de cara, como Invocations, numero de erros, concorrência e afins não vão mais fazer tanto sentido.</p><p>Existem algumas iniciativas do <strong>New Relic</strong> e <strong>Dashbird</strong> pra isso, mas quando o seu tracing precisar ser mais detalhado, você ainda vai precisar correr pra soluções mais granulares e vai perceber que são as mesmas “feijão com arroz”, como o <strong>CloudWatch</strong> e o <strong>X-Ray</strong> pra monitoramento distribuido.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EYM25V_drBPhe-W9eHzS7w.png" /></figure><p>Segue minhas alternativas:</p><ul><li><a href="https://docs.newrelic.com/docs/integrations/new-relic-integrations/getting-started/introduction-infrastructure-integrations"><strong>New Relic (Infraestructure Integration)</strong></a></li><li><a href="https://dashbird.io"><strong>Dashbird</strong></a></li><li><a href="https://aws.amazon.com/pt/cloudwatch/"><strong>Cloudwatch Logs + Dashboard</strong></a></li><li><a href="https://aws.amazon.com/pt/xray/"><strong>X-Ray Tracing</strong></a></li></ul><h4>Resumo</h4><ul><li>Não é tão simples quanto te disseram;</li><li>Serverless não mata o DevOps, muito pelo contrário, torna muito mais necessária a adoção das práticas e cultura;</li><li>Todos os anos de aprendizado sobre qualidade de software podem ser reaproveitados;</li><li>Nem tudo precisa ser reinventado, existe um legado de ouro deixado por outros paradigmas de desenvolvimento;</li><li>O desenvolvedor precisa sim trabalhar localmente;</li><li>A segurança deve ser levada em consideração;</li><li>O multistage é uma realidade;</li><li>Ainda é necessário utilizar pipelines de entrega pra escalar seu time;</li><li>Ainda são necessárias ferramentas pra garantir a qualidade do código;</li><li>Qualidade do processo de desenvolvimento continua o mesmo;</li><li>Monitore tudo, mas tudo mesmo!</li></ul><p>Espero ter ajudado, vlw pessoal! :D</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=40e4e5e50470" width="1" height="1" alt="">
